@INPROCEEDINGS{KITTI2012,
    author={Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
    booktitle={IEEE Conference on Computer Vision and Pattern Recognition}, 
    title={Are we ready for autonomous driving? The KITTI vision benchmark suite}, 
    year={2012},
    volume={},
    number={},
    pages={3354-3361},
    doi={10.1109/CVPR.2012.6248074}
}

@INPROCEEDINGS{Vaidis2023Iros,
    author={Vaidis, Maxime and Dubois, William and Daum, Effie and LaRocque, Damien and Pomerleau, Fran√ßois},
    booktitle={IEEE International Conference on Intelligent Robots and Systems (IROS)}, 
    title={Uncertainty analysis for accurate ground truth trajectories with robotic total stations}, 
    year={2023},
    volume={},
    number={},
}

@article{Euroc2016,
    author = {Burri, Michael and Nikolic, Janosch and Gohl, Pascal and Schneider, Thomas and Rehder, Joern and Omari, Sammy and Achtelik, Markus W. and Siegwart, Roland},
    title ={The EuRoC micro aerial vehicle datasets},
    journal = {The International Journal of Robotics Research},
    volume = {35},
    number = {10},
    pages = {1157-1163},
    year = {2016},
    doi = {10.1177/0278364915620033},
    URL = {https://doi.org/10.1177/0278364915620033},
    eprint = {https://doi.org/10.1177/0278364915620033},
    abstract = { This paper presents visual-inertial datasets collected on-board a micro aerial vehicle. The datasets contain synchronized stereo images, IMU measurements and accurate ground truth. The first batch of datasets facilitates the design and evaluation of visual-inertial localization algorithms on real flight data. It was collected in an industrial environment and contains millimeter accurate position ground truth from a laser tracking system. The second batch of datasets is aimed at precise 3D environment reconstruction and was recorded in a room equipped with a motion capture system. The datasets contain 6D pose ground truth and a detailed 3D scan of the environment. Eleven datasets are provided in total, ranging from slow flights under good visual conditions to dynamic flights with motion blur and poor illumination, enabling researchers to thoroughly test and evaluate their algorithms. All datasets contain raw sensor measurements, spatio-temporally aligned sensor data and ground truth, extrinsic and intrinsic calibrations and datasets for custom calibrations. }
}

@INPROCEEDINGS{UZH2019,
    author={Delmerico, Jeffrey and Cieslewski, Titus and Rebecq, Henri and Faessler, Matthias and Scaramuzza, Davide},
    booktitle={International Conference on Robotics and Automation (ICRA)}, 
    title={Are We Ready for Autonomous Drone Racing? The UZH-FPV Drone Racing Dataset}, 
    year={2019},
    volume={},
    number={},
    pages={6713-6719},
    doi={10.1109/ICRA.2019.8793887}
}